# 컴퓨터 구조의 발전 과정
<br/>

현재 수많은 종류의 컴퓨터들이 존재하고 있지만, 대부분은 앞 절에서 설명한 기본적인 구조와 동작 원리에 기반을 두고 있다.
초기의 컴퓨터들도 그러한 원리에 바탕을 두고 있었지만, 릴레이(relay)와 같은 기계식 부품들을 이용하여 만들어졌다.
그 후에 주요 부품들이 트랜지스터나 반도체 집적회로(semiconductor integrated circuit : IC) 칩으로 대체되면서, 컴퓨터의 처리 속도가 계속 높아지고 있다.
또한 반도체 기억장치 칩의 밀도가 높아짐에 따라 저장 용량도 크게 증가되고 있다.
특히 최근에는 시스템 성능을 높이기 위하여 한 시스템 내에 장착되는 CPU의 수를 증가시키거나, 하나의 침에 여러 개의 CPU 코어(core)들을 포함시키기도 하며,
구성 요소들 간의 연결 통로를 고속화하기 위한 새로운 상호연결 구조를 개발하는 등, 많은 개선이 이루어지고 있다.
그러나 흥미로운 사실은 이러한 발전이 계속되는 중에도 컴퓨터의 근본적인 설계 갠며은 크게 바뀌지 않고 있다는 점이다.

그러면 수십 년간 계속되고 있는 컴퓨터 기술의 발전에도 불구하고, 거의 모든 컴퓨터 구조들의 근간이 되어온 그러한 설계 개념은 언제 누구에 의해 제안되었는가?
여기서는 그 개념이 제안되었던 당시에 구현된 초기 컴퓨터들의 구조를 간략히 분석하고 그 이후의 발전 경위를 살펴봄으로써, 앞으로의 공부에 도움을 주고자 한다.
<br/>
<br/>
## 1. 초기 컴퓨터들의 구조
컴퓨터의 역사는 기계장치들의 자동적으로 네 가지 기본 연산(덧셈, 뺄셈, 곱셈, 나눗셈)을 처음으로 수행할 수 있게 된 17세기로부터 시작된다.
관심을 가질만한 첫 번째 컴퓨터는 1642년에 프랑스의 철학자이며 과학자였던 Blaise Pascal에 의해 만들어졌다.
이것은 덧셈과 뺄셈을 수행하는 기계적인 카운터였는데, 다이얼의 위치에 따라 10진수를 표시하는 여섯 개의 원형판 두 세트로 구성되었다.
각 원형판은 일시적으로 숫자를 기억하는 레지스터로도 사용되었다.
몇 년 후인 1671년에 독일의 철학자이며 수학자인 Gottfried Leibniz는 덧셈과 뺼셈뿐 아니라 곱셈과 나눗셈도 할 수 있는 계산기를 만들었다.
Leibniz의 기계는 Pascal의 계산기에 두 개의 원형판들을 추가하여, 반복적 방법(iterative method)으로 곱셈과 나눗셈을 수행할 수 있게 하였다.
Leibniz의 기계는 네 가지 기능을 가진 계산기라고도 불리며, 그 이후 많은 계산 기계들의 조상이 되었다.

19세기가 되어 현대 컴퓨터의 할아버지로 불리는 Charles Babbage라는 영국인에 의해 계산기 개발 기술은 새로운 단계로 접어들게 된다.
먼저 그는 간단하면서도 수없이 반복되는 수학 연산들을 사람 대신에 정확하게 계산해줄 수 있는 계산 기계의 개발을 시도하였는데, 첫 번째 기계는 Difference Engine이었다.
Difference Engine은 표에 있는 수들을 자동적으로 계산하고, 그 결과를 금속 천공기를 거쳐서 프린트하도록 설계되었다.
Difference Engine은 Pascal의 계산 기계와 마찬가지로 덧셈과 뺄셈만 수행할 수 있었다.
> **Difference Engine**
> : 산술연산(덧셈, 뺄셈) 및 프린트 기능을 가진 최초의 계산기계

이어서 Babbage는 어떠한 수학 연산도 자동적으로 수행할 수 있는 일반목적용 기계인 Analytical Engine을 개발하였다.
아래 그림은 그 기계의 최종적인 설계 구조를 보여주고 있다. 주요 구성 요소로는 기본적인 네 가지 산술 연산들으르 수행하는 연산 장치인 Mill과 기억장치인 Store가 있다.
그리고 입력장치로는 카드 판독기, 출력장치로는 프린터와 카드 천공기가 각각 접속되었다.

동작 원리를 보면, 연산 카드(operation card)에 의해 Mill이 수행할 연산이 지정되고, 그 연산에 사용될 데이터의 주소는 변수 카드(variable card)에 의해 지정된다.
그러면 Mill은 Store 내의 지정된 위치로부터 데이터를 읽어와 레지스터에 저장하고, 연산을 수행한 후에 결과 값을 다시 Store에 저장한다.
여기서 연산 카드와 변수 카드의 내용을 합한 것이 현대 컴퓨터의 프로그램 코드에 해당한다.

#### [Analytical Engine의 기본 구조]
<img src="" width="" height=""/><br/>

그 이전에 개발되었던 다른 게산드로가 비교해볼 때, 이 기계의 주요 장점은 일반목적용이라는 점과 프로그래밍이 가능하다는 것이었다.
또다른 기술적인 혁신은 프로그램의 실행 순서를 변경할 수 있다는 점이었다. 그 방법은 수의 부호를 조사하여 그 결과에 따라 프로그램 실행 순서를 변경하는 것이다.
또한 제어 카드를 이용하여 원하는 명령어의 실행 순서를 정방향(forward) 혹은 역방향(backward)으로 바꾸는 것도 가능하였다.
즉, 이 기계에서 Babbage는 조건 분기(conditional branch) 명령어를 고안하였던 것이다.
이와 같이 Analytical Engine은 현대 컴퓨터의 주요 요소들인 기억장치, CPU 및 I/O 장치를 모두 포함하고 있었으며, 프로그램 언어도 사용하였다.

Analytical Engine은 주요 부품들이 모두 기계적인 장치들이었기 때문에 속도가 느렸고 신뢰도가 낮다는 단점을 가지고 있었다.
그 후 1900년대에 들어와서 진공관이 발명되면서 그러한 단점들이 개선될 수 있었고, 진공관을 이용한 최초의 전자식 컴퓨터인 ENIAC(Electronic Numerical Integrator And Computer)이
펜실베니아 대학에서 개발되었다. 그러나 이 컴퓨터의 가장 큰 단점은 프로그램을 저장하고 변경하는 것이 불가능하다는 점이었다.

프로그램과 데이터를 기억장치에 저장하고 변경할 수도 있다면 컴퓨터를 훨씬 더 편리하게 사용할 수 있게 된다.
'Stored-program'으로 알려진 이 개념은 ENIAC의 설계자이며 수학자인 폰노이만(von Neumann)에 의해 제안되었다. 연구 논문을 통하여 발표하였던 그의 설계 개념은 다음과 같다.
- 2진수 체계(binary number system)를 사용한다.
- 프로그램과 데이터를 내부에 저장한다.

이 개념은 폰노이만이 새로운 컴퓨터인 EDVAC(Electronic Discrete Variable Automatic Computer)의 개발을 위하여 1945년에 처음 발표하였다.

1946년에 폰노이만과 그의 동료들은 IAS 컴퓨터라고 불리는 새로운 컴퓨터 개발을 시작하였다.
IAS 컴퓨터는 1952년에 완성되었으며, 그 이후에 출현한 거의 모든 일반목적용 컴퓨터들의 기본형이 되었다.
아래는 IAS 컴퓨터의 일반적인 구조를 보여주고 있는데, 다음과 같은 부분들로 구성되어 있다[BUR46][STA06].
> **IAS 컴퓨터**
> : 폰노이만의 설계개념을 적용하여 프로그램 저장과 변경이 가능하도록 구현된 최초의 디지털컴퓨터.

#### [IAS 컴퓨터의 구조]
<img src="" width="" height=""/><br/>

- 프로그램 제어 유니트 (Program Control Unit)
- 산술논리연산장치 (ALU)
- 주기억장치
- 입출력장치

프로그램 제어 유니트는 주기억장치로부터 명령어들을 한 개씩 가져와서 실행함으로써 IAS를 작동시킨다. 주기억장치에는 명령어와 데이터가 모두 저장된다.
이 구조에서 특기할 사항으로는 주기억장치로부터 한 번에 읽혀오는 명령어의 수가 두 개씩이라는 점이다.
그 중의 하나는 즉시 프로그램 제어 유니트로 보내져 실행되며, 다른 하나는 일단 명령어 버퍼에 저장되어 있다가 다음 명령어 실행 사이클에서 실행되는데,
결과적으로 명령어 인출을 위한 기억장치 액세스 시간이 단축된다.
이 방법은 현대의 컴퓨터들에서도 사용되고 있는 명령어 선인출(instruction prefetch)과 유사한 것으로서, 이러한 개념이 그 당시에 이미 사용되었다는 것은 매우 놀라운 사실이다.
여기서 각 유니트의 내부 구조와 기능들에 대한 설명은 생략하기로 한다.

이와 같이 폰노이만의 설계 개념이 적용되었던 초기의 컴퓨터인 IAS의 구조가 현대 컴퓨터들과 근본적으로는 차이가 없다는 것을 알 수 있다.
바꾸어 말하면, 그 때 제안되었던 설계 개념이 이후의 거의 모든 컴퓨터 설계들에 있어서 근간이 되어왔다. 이러한 컴퓨터들에서는 프로그램이 순차적으로 실행된다.
즉, 특별한 이유가 없는 한, 프로그램 코드들은 기억장치에 저장된 순서대로 실행되며, 그 주소는 CPU의 내부 레지스터인 프로그램 카운터(program counter)에 의해 저장되었다.
이러한 구조설계 개념을 폰노이만 아키텍처(von Neumann Architecture)라고 부른다.
> **폰노이만 아키텍처**(von Neumann Architecture)
> : 폰노이만이 제안한 컴퓨터구조 설계 개념으로서, 기억장치에 저장된 프로그램을 프로그램 카운터(program counter)가 지정하는 순서대로 실행시킴
<br/>

## 2. 주요 컴퓨터 부품들의 발전 경위
컴퓨터 구조의 발전 과정을 살펴보기 위해서는 먼저 주요 컴퓨터 부품들의 발전 과정과 동향을 파악하는 것이 도움이 된다.
앞에서 설명하였던 초기의 전자식 컴퓨터에 있어서 최초의 중요한 변화는 진공관을 **트랜지스터**(transistor)로 대체하는 데서 나타났다.
1940년대에 개발된 트랜재스터는 진공관보다 작고 싸며 더 적은 열을 발산하지만, 컴퓨터를 만드는 데 있어서 진공관과 같은 방식으로 사용될 수 있었다.
전선과 금속판들, 그리고 유리 캡슐과 진공을 필요로 하는 진공관(vacumm tube)과는 달리, 트랜지스터는 실리콘(silicon: 규소)이라는 반도체 물질을 이용하여 만들어진다.

컴퓨터의 주요 부품으로 트랜지스터가 사용되면서, 진공관을 이용하여 구현되었던 기존의 컴퓨터들을 제1세대 컴퓨터로 구분하고, 이들을 제2세대 컴퓨터로 분류하게 되었다.
제2세대의 초기 컴퓨터들은 대략 1000개 정도의 트랜지스터들로 구성되었다.
그러나 컴퓨터의 기능이 확대되고 저장장치 용량이 증가함에 따라 부품들의 수는 계속 늘어났고, 트랜지스터를 이용하여 대용량 컴퓨터를 제작하는 것도 점차 더 어려워지게 되었다.
그러던 중 1958년에 전자공학의 혁명이 일어나 반도체공학 분야의 획기적인 새로운 기술이 출현하는데, 그것이 바로 **집적회로**(Integrated Circuit : IC)의 발명이었다.
그와 함께 컴퓨터 분류는 IC 시대로 정의되는 제3세대로 넘어가게 된다.
> **집적회로**(IC)
> : 실리콘 반도체 칩에 다수의 트랜지스터들을 넣어(직접 시켜) 제조한 전자부품

이와 같이 컴퓨터의 세대는 주로 새로운 하드웨어 부품의 출현을 기준으로 분류되고 있다.
그런데 부품들의 집적도와 속도가 계속 높아지고 있기 때문에, 새로운 세대로 바뀔 때마다 컴퓨터는 이전 세대의 컴퓨터들보다 더욱 고속화되고, 기억 용량이 증가되며,
크기는 줄어드는 특징을 보이고 있다.

아래는 IC 칩(chip)의 제조 과정을 보여주고 있다.
#### [IC 칩의 제조 과정]
<img src="" width="" height=""/><br/>

먼저 반도체 재료인 실리콘을 추출하여 만든 원기둥 모양의 실리콘 성형을 수평 방향으로 얇게 자르면 그림에서 보는 것과 같은 원형판 모양의 **실리콘 웨이퍼**(silicon wafer)를
만들 수 있다. 이 웨이퍼를 매트릭스 형태의 작은 영역들로 나누면 각각은 수 평방 밀리미터 크기의 사각형 평판이 된다.
이 사각형 평판 위에 동일한 회로 패턴을 집적(integrate) 시키면 여러 개의 게이트들을 포함하는 IC 칩이 제조되는 것이다.
그런 다음에는 이 칩의 회로 부분을 보호하기 위해 플라스틱과 같은 재료를 이용하여 패키징한 다음에, 외부와의 연결을 위한 핀(pin)들을 부착한다.
이렇게 만들어진 칩들은 **인쇄회로기판**(printed circuit board: PCB) 위에서 서로 연결되어, 더 크고 복잡한 회로를 구성하는 데 사용된다.
> **실리콘 웨이퍼**(silicon wafer)
> : 반도체 칩의 재료인 실리콘을 수평 방향으로 절단하여 만든 원형판

> **인쇄회로기판**(PCB)
> : 전자회로들 간의 연결을 위한 회로 선들을 미리 부착시켜놓은 기판

- **SSI**(Small Scale IC)
  - 수십 개의 트랜지스터들이 집적되는 소규모 IC로서, 주로 기본적인 디지털 논리 게이트(digital logic gate)들을 포함하는 칩으로 제조되고 있다.
- **MSI**(Medium Scale IC)
  - 수백 개의 트랜지스터들이 집적되는 IC 칩으로서, 카운터(counter), 해독기(decoder) 혹은 시프트 레지스터(shift register)와 같은 조합회로나 순차회로를 포함하는 칩으로 제조되고 있다.
- **LSI**(Large Scale IC)
  - 수천 개의 트랜지스터들이 집적되는 대규모 IC로서, 8-비트 마이크로프로세서 칩이나 소규모 반도체 기억장치 칩들이 이 분류에 속한다.
- **VLSI**(Very Large Scale IC)
  - 수만 내지 수십만 개 이상의 트랜지스터들이 집적되는 대규모 IC로서, 마이크로프로세서 칩들과 대용량 반도체 기억장치 칩들이 이 분류에 속한다.
- **ULSI**(Ultra Large Scale IC)
  - 수백만 개 이상의 트랜지스터들이 집적되는 32-비트급 이상의 마이크로프로세서 칩들과 수백 메가바이트 이상의 반도체 기억장치 칩들 및 앞으로 출현할 고밀도 반도체 칩들을
    지칭하기 위한 용어로서 VVLSI(Very Very Large Scale IC)라고도 불리지만, 공식적으로 통용되는 용어는 아니다.

이와 같이 높은 집적도의 IC 칩들이 컴퓨터의 부품으로 사용됨에 따라 다음과 같은 이점들을 얻을 수 있게 되었다.
- 회로들이 더 근접하게 됨으로써 전기적 통로의 길이가 줄어들어 동작 속도가 크게 상승하게 되었다.
- 컴퓨터의 크기가 대폭 줄어들었다.
- 회로들 간의 상호 연결이 칩 내부에서 이루어지기 때문에 부품들의 신뢰성이 높아졌다.
- 전력 소모가 줄어들고 냉각장치가 간단해졌다.
- 집적도가 높아져도 칩의 가격은 거의 변하지 않았기 때문에, 결과적으로 컴퓨터의 가격이 하락하게 되었다.

마이크로프로세서를 등장시킨 LSI 기술이 개발된 시점부터 컴퓨터 세대는 제4세데ㅐ로 구분된다. 이 세대에서는 개인용 컴퓨터가 출현하였고, 초고속 슈퍼컴퓨터들이 개발되었다.
그 다음 세대인 제5세대는 아직 명확하게 구분되지 않고 있으나, 부품의 집적도 보다는 시스템 규모 혹은 인공지능과 같은 획기적인 응용 소프트웨어의 출현에 의하여 정의될
가능성도 있다. 또한 광 컴퓨터(optical computer) 혹은 신경망 컴퓨터(neural computer) 등의 개발이 성공된다면, 새로운 컴퓨터 세대를 구분하게 되는 계기가 될 수도 있을 것이다.
<br/>
<br/>
## 3. 컴퓨터시스템의 분류와 발전 동향
앞에서 소개하였던 초기의 컴퓨터들 및 그에 기반하여 IBM이 개발하였던 컴퓨터시스템들은 모두 그 당시로서는 대형 메인프레임(mainframe) 시스템이었으며,
가격이나 크기 때문에 정부기관이나 대규모 회사 혹은 대학에서만 보유할 수 있었다.
그 후 DEC가 개발한 PDP-8 시스템을 시작으로 미니컴퓨터(minicomputer) 시대가 열리면서 컴퓨터시스템들은 대형 컴퓨터와 미니컴퓨터라는 두 가지 분류로 나누어지게 되었다.
미니컴퓨터는 대형 컴퓨터에 비하여 가격이 10분의 1 이하였기 때문에, 그 때부터 대학의 실험실이나 일반회사의 단위부서에서도 컴퓨터를 별도로 보유할 수 있게 된 것이다.

1970년대에 들어와 **마이크로프로세서**(microprocessor)가 출현하면서 컴퓨터의 크기가 더욱 줄어들고 가격도 급속히 하락함에 따라, 1980년대 초부터 개인도 컴퓨터를 보유할
수 있게 되었다. 대형 메인프레임 컴퓨터가 주류를 이루던 초기에 비하여 미니컴퓨터가 출현한 이후에 컴퓨터 시장과 응용 분야가 크게 확대되었던 것과 마찬가지로,
개인이 컴퓨터를 소유하게 되면서 컴퓨터 보급이 크게 확산되었을 뿐만 아니라 사회적으로 큰 변화가 일어나게 되었다.
즉, 그때까지 컴퓨터의 주요 용도는 고속 산술적 계산이나 데이터베이스 관리 등으로 한정되어 있었으나, 개인용 컴퓨터의 보급과 더불어 그러한 용도 외에도 문서 작성, 오락이나
취미 활동, 인터넷 활용 등으로 컴퓨터 응용 분야가 크게 확대되었다. 이러한 컴퓨터 기술의 발전은 컴퓨터 네트워크의 고속화와 연계하여 정보화 사회의 출현을 촉진하는 계기가 되었다.
> **마이크로프로세서**(microprocessor)
> : CPU 내부 회로 전체를 하나의 반도체 칩에 넣어 제조한 IC로서, 컴퓨터의 크기 감소 및 가격 하락에 지대한 영향을 미친 혁신적 전자부품

이러한 변화 속에서 컴퓨터 설계자들과 제조회사들의 계속적인 목표는 더 빠르면서도 더욱 작고 저렴한 컴퓨터를 개발하는 것이었다.
컴퓨터 사용자들은 용도와 예산에 맞추어 적절한 컴퓨터를 구입하길 원하였고, 그에 따라 다양한 성능과 가격대의 컴퓨터시스템들이 출현하게 되었다.
이 절에서는 성능, 크기 및 가격에 따라 분류되고 있는 여러 종류의 컴퓨터들의 구조적 특징을 개괄적으로 소개하고, 각각의 발전 동향에 대하여 살펴보고자 한다.

### 1) 개인용 컴퓨터
마이크로프로세서라는 획기적인 반도체 칩의 출현과 더불어 개발되기 시작한 **개인용 컴퓨터**(personal computer: PC)는 크기가 작고 가격도 저렴하지만, 구조적 측면에서 볼 때는
다른 컴퓨터 분류들과 근본적으로 다르지 않다. 즉, 컴퓨터의 기능을 수행하는데 필요한 기본적인 구성 요소들을 모두 갖추고 있다.
최근에 개발되고 있는 개인용 컴퓨터의 성능은 수십 년 전의 대형 메인프레임 컴퓨터의 성능을 앞지르고 있다.
이러한 성능 향상은 물론 고성능 마이크로프로세서의 개발에 기인하고 있지만, 그 외의 다른 부품들(기억장치, 상호연결망 등)의 고집적화와 고속화도 주요 요인이 되고 있다.
개인용 컴퓨터의 발전 과정에서 컴퓨터 구조상의 주요 동향을 분석해보면 다음과 같다.
> **개인용 컴퓨터**(personal computer)
> : 개인이 소유할 수 있는 수준의 크기와 가격대의 컴퓨터에 대한 통칭으로서, 최근에는 용도와 크기 면에서 다양한 형태들이 출현하고 있다.

- 성능이 개선된 새로운 마이크로프로세서들이 계속적으로 등장하고, 그에 따라 PC의 성능이 꾸준히 향상되고 있다.
  최초의 PC 모델은 8비트급이었으나, 그 이후 16-비트 및 32-비트 컴퓨터로 단어 길이가 증가하면서 발전해왔다.
  기본적인 데이터 처리 단위는 32비트이지만, 64비트 단위의 데이터 처리 및 기억장치 주소를 사용하는 PC들도 출시되고 있다.
- CPU 내부 구조가 다수의 ALU들 혹은 명령어 실행 유니트들을 포함하는 슈퍼스칼라 구조로 발전함에 따라, 명령어 처리 속도가 크게 향상 되었다.
  또한 원래의 프로그램 순서와는 다르게 명령어들을 실행하는 out-of-order execution 방식의 도입도 성능 향상에 많은 도움이 되었다.
  최근에는 하나의 칩 내에 여러 개의 CPU 코어들을 포함시킨 멀티-코어 프로세서(multi-core processor)들도 출현하면서 프로그램 처리 속도가 점차 더 높아지고,
  여러 응용 프로그램들을 동시에 처리하는 것도 가능하게 되었다.
- 칩의 집적도가 높아지면서 주변 요소들이 CPU 칩 내부에 포함됨에 따라, 속도와 신뢰도가 크게 향상되었다.
- GPU(Graphic Processing Unit)를 계산보조장치로 사용함으로써 고속 그래픽 처리뿐 아니라 복잡한 과학기술 계산들도 높은 속도로 처리할 수 있게 되었다.
- 주기억장치와 보조저장장치의 용량이 크게 증가하고 있으며, 그 종류도 다양해지고 있다.

PC는 응용 분야가 확대되어 보급이 크게 늘어나면서 용도와 크기 및 가격대가 더욱 다양해지고 있기 떄문에 명칭도 세분화되고 있다.
기본적인 PC 형태는 책상위에 설치하는 크기라는 의미에서 데스크탑 컴퓨터(desktop computer)라고 불리며, 이동시 휴대할 수 있는 크기의 노트북 컴퓨터(notebook computer)가
그와 구분된 명칭을 가지고 있다. 긜고 제한된 용도를 가지는 형태로서, 웹사이트의 콘텐츠 및 전자우편 열람 정도의 기본적인 인터넷 위주 작업에 이용하는 것을 목적으로 한
넷북(netbook)은 노트북보다 가격이 더 저렴하고 가볍게 제조된다.
또한 주변장치를 최소화시킨 형태인 태블릿 PC(tablet PC)는 터치스크린을 주입력장치로 장착한 휴대용 PC이며, 포켓 PC(pocket PC)는 크기를 더욱 줄였다는 장점이 있지만
성능과 기능이 제한되어 PDA(personal digital assistant) 용도로만 사용되고 있다.
이와 같은 초소형 휴대용 PC들은 공통적으로 내부 하드웨어가 단순하며, 성능보다는 전력소모량과 크기를 최소화시키는 것이 설계상의 목표가 된다.

### 2) 임베디드 컴퓨터
각종 기계장치나 전자장치들의 내부에 포함되어, 그 장치들의 동작을 제어(control)하는 컴퓨터들을 일컬어 **임베디드 컴퓨터**(embedded computer; 내장 컴퓨터라고도 함)라고 부른다.
최근 컴퓨터 산업에서 수요가 가장 급속히 확대되고 있는 임베디드 컴퓨터는 각종 가전제품이나 컴퓨터 주변기기, 이동 전화기, 비디오 게임기, 자동차 등에 내장되고 있다.
이 분류의 컴퓨터는 프로세서와 기억장치 및 I/O 인터페이스 회로를 모두 하나의 칩에 집적시킨 8-비트 마이크로컨트롤러(micro-controller)를 이용한 초소형에서부터 32-비트
컴퓨터에 이르기까지 처리 속도와 크기 면에서 매우 다양하다.
가격도 1달러 정도부터 수 백 달러에 이르기까지 다양하게 구성될 수 있는데, 일반적으로 최소의 비용으로 필요한 만큼의 성능을 가지도록 설계된다.

임베디드 컴퓨터들은 실시간(real-time)으로 프로그램을 처리해야 하는 경우가 많다. 즉, 외부 신호를 받아서 그에 대한 프로그램 처리를 반드시 정해진 시간 내에 완료해야 한다.
그 요구 조건을 만족시키기 위하여 일반적으로 각 응용에 맞게 특수 설계된 하드웨어와 소프트웨어를 결합한 형태를 가진다.
다른 주요 특징은 기억장치 용량과 전력 소모량을 최소화할 수 있도록 설계해야 한다는 점이다.
임베디드 컴퓨터는 사물 인터넷(internet of things : IoT) 및 지능형 로봇(intelligent robot)의 핵심 요소로도 사용되기 때문에 더욱 다양해지고 보급도 확대될 전망이다.

### 3) 서버급 컴퓨터시스템
초기의 미니컴퓨터 수준의 시스템들이 최근에는 워크스테이션과 슈퍼미니컴퓨터로 구분되어 발전하고 있다.
먼저 **워크스테이션**(workstation)은 대부분 64-비트 마이크로프로세서를 CPU로 사용하고 있으며, 고속 그래픽 처리를 위한 하드웨어들을 가지고 있어서 3차원 동영상처리,
시뮬레이션, 혹은 컴퓨터를 이용한 설계(CAD)와 같은 응용들에 널리 사용되고 있다. 대부분의 워크스테이션들은 운영체제(OS)로서 UNIX나 LINUX를 사용하고 있다.
그러나 최근에는 개인용 컴퓨터의 성능이 급속히 향상됨에 따라 워크스테이션의 보급은 미미해지고 있다.
**슈퍼미니컴퓨터**(super-minicomputer)는 과거의 VAX-11으로 대표되는 미니컴퓨터들보다 수십 배 이상의 처리 속도를 가지는 시스템으로서, 그러한 성능을 가지기 위하여
한 시스템 내에 20개 이상의 프로세서들을 포함하는 **다중프로세서시스템**(multiprocessor system)으로 구성되고 있다.
일반적으로 채택되고 있는 시스템 구조는 아래에서 보는 바와 같이 하나의 시스템 버스에 다수의 프로세서들과 주기억장치 및 I/O 장치들이 모두 접속되어 있다.
이러한 시스템의 프로세서로는 64-비트 마이크로프로세서들이 주로 사용되고 있다.
#### [다중프로세서시스템의 구조]
<img src="" width="" height=""/><br/>

> **워크스테이션**(workstation)
> : 고속 그래픽처리 및 시뮬레이션 등에 사용되는 64-비트 고성능 컴퓨터

> **슈퍼미니컴퓨터**(super-minicomputer)
> : 미니컴퓨터의 수십 배 성능을 가지는 서버급 컴퓨터시스템

최근에 네트워크 설비가 확충되고 중형 서버급 시스템들의 성능과 저장 용량이 계속 상승함에 따라, 하나의 대형 시스템을 사용하기보다는 여러 개의 중형 서버급 컴퓨터시스템들을
네트워크에 접속하여 응용(혹은 용도)별로 구분하여 사용하는 컴퓨팅 환경을 구축하는 경향으로 가고 있다.
이것을 컴퓨터의 다운사이징(downsizing)이라고 하며, 중형 서버급 시스템들이 그러한 변화를 주도하고 있는 것이다.
그들은 최근에 인터넷 웹서버로서도 널리 사용되고 있는데, 웹사이트의 규모에 따라 다양한 시스템 사양(프로세서 수, 주기억장치 및 보조저장장치의 용량)하여 가격대비성능비
(cost/performance ratio)를 쉽게 조정할 수 있기 때문이다.
> **다운사이징**(downsizing)
> : 대형컴퓨터를 이용한 중앙집중식 처리 방식에서 여러 대의 중형급 시스템들을 이용한 응용별 처리 방식으로 바뀌어가는 현상
<br/>

## 4) 대형 메인프레임 컴퓨터
초기의 컴퓨터 시장을 석권하였던 IBM이 1960년대에 개발한 System/360 및 370 계열의 메인프레임 컴퓨터시스템들은 그 후에 3081, 3090 등으로 계속 발전해왔으며,
최근에는 시스템 보안 및 통신 기능이 대폭 강화된 IBM zEnterprise 계열이 보급되고 있다 [SHU13].
이러한 시스템들은 대용량 저장장치를 보유하며 다중 I/O 채널(multiple I/O channel)을 이용한 고속 I/O 처리 능력을 가지고 있기 때문에, 주로 정부기관이나 은행, 대형
인터넷포털사이트 등에서 대규모 데이터베이스(빅 데이터) 저장 및 관리용으로 사용되고 있다.

### 5) 슈퍼컴퓨터
현존하는 컴퓨터들 중에서 속도가 현저히 높은 컴퓨터들을 **슈퍼컴퓨터**(supercomputer)라고 부른다.
슈퍼컴퓨터를 구분해주는 성능상의 수치는 명확히 정의되어 있지 않지만, 처리 속도와 기억장치 용량에 있어서 그 시대의 다른 컴퓨터들에 비하여 상대적으로 월등한
컴퓨터시스템들을 슈퍼컴퓨터로 분류하고 있다.
예를 들어, 1970년대 초에 개발된 최초의 슈퍼컴퓨터인 CRAY-1은 속도가 100 MFLOPS 정도였으며, 최근에는 그보다 수백만 배 이상 빨라진 페타플롭스(PELOPS) 급의 속도를
가져야 슈퍼컴퓨터로 분류될 수 있다. 현재 슈퍼컴퓨터로 분류디고 있는 시스템들도 수년 후에 더 높은 성능의 컴퓨터들이 개발되면 더 이상 슈퍼컴퓨터로 불리지 않을 것이다.
즉, 슈퍼컴퓨터에 대한 분류 기준은 계속 높아지고 있다.

슈퍼컴퓨터의 주요 응용 분야들을 보면, VLSI 회로설계, 항공우주공학, 천문학(일기예보), 구조공학, 유전탐사, 핵공학, 인공지능, 입체영상처리 등과 같은 대규모 과학계산 및
시뮬레이션에 사용된다. 슈퍼컴퓨터는 구조적 특징에 따라 다음과 같이 세 가지로 구분될 수 있다.
- 파이프라인 슈퍼컴퓨터 (pipeline supercomputer)
- 대규모 병렬처리시스템 (masively parallel processing system: MPP)
- 클러스터 컴퓨터 (cluster computer)

**파이프라인 슈퍼컴퓨터**는 하나의 CPU 내에 다수의 연산 장치들이 포함되어 있으며, 각 연산 장치는 고도로 파이프라이닝 되어 있어서 매우 높은 계산 능력을 가지고 있다.
최근에는 그와 같은 초고속 CPU들을 여러 개 서로 연결하여 시스템을 구성함으로써 성능을 더욱 높이고 있다.
초기의 슈퍼컴퓨터들이 주로 이러한 구조를 가졌는데, 대표적인 시스템들로는 미국의 CRAY Y-MP, CRAY-2 및 일본의 Fujitsu VP2000, VPP500 등이 있ㄷ.
> **파이프라인 슈퍼컴퓨터**(pipeline supercomputer)
> : 고도로 파이프라이닝 된 구조를 가진 소수의 CPU들을 이용하여 구성되는 슈퍼컴퓨터

**대규모 병렬처리시스템**(MPP)는 한 시스템 내에 상호연결된 수만 혹은 수십만 개 이상의 프로세서들을 포함하고 있으며, 그들은 하나의 큰 작업을 분할하여 동시에 수행하는
병렬처리(parallel processing) 기술을 사용한다. 이러한 시스템들은 점차 대형화되어 더욱 성능이 높아지고 있는 추세인데, 구조 설계에 있어서 핵심은 프로세서들 간의 통신
시간을 최소화할 수 있는 상호연결망(interconnection network)을 설계하는 것이다.
여기서는 이 분류에 속하는 시스템의 한 예로서, 미국 Lawrence Livermore 국립연구소에 설치된 IBM BlueGene/Q 슈퍼컴퓨터의 구성도를 간략히 살펴보기로 하자.
#### [IBM BlueGene/Q 슈퍼컴퓨터의 구성도 [GIL 13]]
<img src="" width="" height=""/><br/>

이 슈퍼컴퓨터는 국제공인 슈퍼컴퓨터 평가 웹사이트(www.top500.org)에서 2018년 11월에 발표한 TOP500 리스트의 최상위에 랭크된 시스템이다.
> **대규모 병렬처리시스템**(MPP)
> : 매우 많은 수의 프로세서들을 이용하여 병렬처리를 수행하도록 설계되는 슈퍼컴퓨터의 구성 방식

> **병렬처리**(parallel processing)
> : 많은 수의 프로세서들이 하나의 큰 작업을 분할하여 동시에 처리하는 기술

따라서 각 노드 보드는 512개의 프로세서들과 512GByte의 기억장치를 포함하게 된다.
그리고 32개의 노드 보드들을 하나의 랙(rack)에 설치한 다음에, 고속 네트워크를 이용하여 96개의 랙들을 상호 연결하였다.
결과적으로, 전체 시스템은 96×512×32=1,572,864개의 프로세서들과 1.57PByte의 기억장치를 포함하는 대규모 병렬처리시스템으로 구성되었다.

IBM은 최근에 BlueGene/Q의 성능을 더욱 발전시킨 시스템들을 미국내 주요 국립연구소에 설치하였는데, 그들은 2018년 11월 기준 TOP500 리스트에서 각각 세계 1위 및 2위로 랭크된
Summit 슈퍼컴퓨터와 Sierra 슈퍼컴퓨터이다.
IBM OpenPOWER 플랫폼을 기반으로 구성되는 그 시스템들 중에서 Summit는 각 컴퓨터 노드가 24-코어 프로세서인 IBM POWER9 CPU와 다수의 NVIDIA Volta GPU들로 구성되어,
노드당 40 TFLOPS의 성능을 가진다. 그러한 노드들 3400개 이상으로 구성된 Summit 시스템은 전체적으로 240만 개의 코어들을 가지고 있으며, 최고 속도가 200 PFLOPS에 달한다.
이 시스템의 그러한 계산 성능은 NVLink라고 부르는 초고속 연결망을 이용하여 CPU와 GPU들을 결합한 혼합형 계산(heterogeneous computing) 방식을 근간으로 하고 있다[NVI14b].

**클러스터 컴퓨터**란 고속 LAN이나 네트워크 스위치에 의해 서로 연결된 PC들 혹은 워크스테이션의 집합체를 말한다[BUY99][HWA99].
클러스터 컴퓨터에서는 그러한 단위 컴퓨터를 노드(node)라고 부르며, 노드들에 포함된 모든 자원들을 **단일 시스템 이미지**(single system image: SSI)로 통합하여 사용한다.
즉, 클러스터 컴퓨터에 포함된 모든 노드들의 프로세서들과 주기억장치 및 디스크들이 **클러스터 미들웨어**(cluster middleware)라고 부르는 시스템 S/W에 의해 통합되어
하나의 큰 시스템으로서 동작하게 된다. 따라서 어느 한 노드에서 로그인(log-in)한 사용자는 전체 클러스터 컴퓨터를 하나의 시스템으로 간주하고 사용할 수 있다.
그리고 만약 클러스터에 포함된 어느 한 컴퓨터에 고장이 발생하더라도 다른 컴퓨터가 그 기능을 대신할 수 있기 때문에, 시스템 신뢰도(system reliability)가 높아진다.
이와 같은 새로운 시스템 통합 기술을 이용하면 저렴한 가격으로 높은 성능과 신뢰도를 가진 병렬컴퓨팅 환경을 구축할 수 있기 때문에, 최근 대형 웹서버 및 슈퍼컴퓨터 설계 개념으로
널리 채택되고 있다.
> **클러스터 컴퓨터**(cluster computer)
> : 고속 LAN이나 네트워크 스위치에 의해 서로 연결된 독립적인 컴퓨터들의 집합체로서 단일 시스템 이미지(single system image)를 형성하여 하나의 큰 시스템으로서 동작하며,
> 최근 슈퍼컴퓨터 분야에서 가장 널리 사용되고 있는 시스템 구성 방식